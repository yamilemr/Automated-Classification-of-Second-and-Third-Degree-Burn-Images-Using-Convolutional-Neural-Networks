{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger\n",
    "\n",
    "from tools import load_images_with_labels, calculate_metrics, evaluate_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtener imágenes y etiquetas de un directorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/burn_images/'\n",
    "width = 540\n",
    "height = 960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_canales = [\"green\", \"blue\"]\n",
    "\n",
    "X, y, n_canales = load_images_with_labels(path, channels=nombre_canales)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separar los datos en entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "print('Shape of X_train:', X_train.shape)\n",
    "print('Shape of X_val:', X_val.shape)\n",
    "print('Shape of y_train:', y_train.shape)\n",
    "print('Shape of y_val:', y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función para hiperparametros\n",
    "Esta función recibe un parámetro y una lista de parámetros y se van probando uno por uno en el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros_base = {\n",
    "    'conv_layers': 3,\n",
    "    'filters_layer_1': 32,\n",
    "    'filters_layer_2': 32,\n",
    "    'filters_layer_3': 64,\n",
    "    'kernel_size': 3,\n",
    "    'strides': 2,\n",
    "    'dense_layers': 1,\n",
    "    'dense_units_1': 64,\n",
    "    'dense_units_2': 64,\n",
    "    'dense_units_3': 64,\n",
    "    'dropout_rate': 0.4,\n",
    "    'batch_size': 32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cambiar_parametro(diccionario, parametro, lista_parametros):\n",
    "    \"\"\"\n",
    "    Cambia el valor de un parámetro en un diccionario y genera un nombre de ejecución.\n",
    "    Args:\n",
    "        diccionario (dict): Diccionario que contiene los parámetros del modelo.\n",
    "        parametro (str): Clave del parámetro que se desea cambiar.\n",
    "        lista_parametros (list): Lista de valores que se asignarán al parámetro.\n",
    "    Yields:\n",
    "        tuple: Un nombre de ejecución (str) y el diccionario actualizado (dict).\n",
    "    Si el parámetro no se encuentra en el diccionario, imprime un mensaje de error y retorna None.\n",
    "    \"\"\"\n",
    "    for valor in lista_parametros:\n",
    "        if parametro in diccionario:\n",
    "            diccionario[parametro] = valor\n",
    "        else:\n",
    "            print(f'El parametro {parametro} no se encuentra en el diccionario')\n",
    "            return None\n",
    "        \n",
    "        nombre_run = (f\"cl:{diccionario['conv_layers']}, \" \n",
    "        + f\"fl1:{diccionario['filters_layer_1']}, \")\n",
    "        \n",
    "        if diccionario['conv_layers'] >= 2: \n",
    "            nombre_run = nombre_run + f\"fl2:{diccionario['filters_layer_2']}, \"\n",
    "        if diccionario['conv_layers'] >= 3: \n",
    "            nombre_run = nombre_run + f\"fl3:{diccionario['filters_layer_3']}, \"\n",
    "\n",
    "        nombre_run = (nombre_run + f\"ks:{diccionario['kernel_size']}, \"\n",
    "            + f\"st:{diccionario['strides']}, \"\n",
    "            + f\"dl:{diccionario['dense_layers']}, \"\n",
    "            + f\"du1:{diccionario['dense_units_1']}, \")\n",
    "        \n",
    "        if diccionario['dense_layers'] >= 2:\n",
    "            nombre_run = nombre_run + f\"du2:{diccionario['dense_units_2']}, \"  \n",
    "        if diccionario['dense_layers'] >= 3:\n",
    "            nombre_run = nombre_run + f\"du3:{diccionario['dense_units_3']}, \"  \n",
    "\n",
    "        nombre_run = (nombre_run + f\"dr:{diccionario['dropout_rate']}, \"\n",
    "            + f\"bs:{diccionario['batch_size']}\")\n",
    "\n",
    "        yield nombre_run, diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear generador de nombres y diccionarios\n",
    "generador_parametros = cambiar_parametro(parametros_base, 'batch_size', [32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A partir de aquí correr para probar los demás valores de la lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_run, parametros = next(generador_parametros)\n",
    "print(nombre_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear Red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primera capa convolucional (se agrega input_shape)\n",
    "arquitectura = [layers.Conv2D(parametros[\"filters_layer_1\"], \n",
    "                              kernel_size=(parametros[\"kernel_size\"], parametros[\"kernel_size\"]), \n",
    "                              strides=(parametros[\"strides\"], parametros[\"strides\"]),\n",
    "                              input_shape=(height, width, n_canales)),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Activation('relu'),\n",
    "                layers.MaxPooling2D(pool_size=(2, 2))]\n",
    "\n",
    "#Capas convolucionales restantes\n",
    "if parametros['conv_layers'] > 1:\n",
    "    arquitectura += [layers.Conv2D(parametros[\"filters_layer_2\"], \n",
    "                                   kernel_size=(parametros[\"kernel_size\"], parametros[\"kernel_size\"]),\n",
    "                                   strides=(parametros[\"strides\"], parametros[\"strides\"])),\n",
    "                    layers.BatchNormalization(),\n",
    "                    layers.Activation('relu'),\n",
    "                    layers.MaxPooling2D(pool_size=(2, 2))]\n",
    "\n",
    "    if parametros['conv_layers'] > 2:\n",
    "        arquitectura += [layers.Conv2D(parametros[\"filters_layer_3\"], \n",
    "                                       kernel_size=(parametros[\"kernel_size\"], parametros[\"kernel_size\"]),\n",
    "                                       strides=(parametros[\"strides\"], parametros[\"strides\"])),\n",
    "                        layers.BatchNormalization(),\n",
    "                        layers.Activation('relu'),\n",
    "                        layers.MaxPooling2D(pool_size=(2, 2))]\n",
    "            \n",
    "#GlobalAveragePooling2D\n",
    "arquitectura += [layers.GlobalAveragePooling2D()]\n",
    "\n",
    "#Capas densas\n",
    "arquitectura += [layers.Dense(parametros[\"dense_units_1\"]),\n",
    "                layers.Activation('relu'),\n",
    "                layers.Dropout(parametros[\"dropout_rate\"])]\n",
    "\n",
    "if parametros['dense_layers'] > 1:\n",
    "    arquitectura += [layers.Dense(parametros[\"dense_units_2\"]),\n",
    "                    layers.Activation('relu'),\n",
    "                    layers.Dropout(parametros[\"dropout_rate\"])]\n",
    "\n",
    "    if parametros['dense_layers'] > 2:\n",
    "        arquitectura += [layers.Dense(parametros[\"dense_units_3\"]),\n",
    "                        layers.Activation('relu'),\n",
    "                        layers.Dropout(parametros[\"dropout_rate\"])]\n",
    "\n",
    "#Capa de salida\n",
    "arquitectura += [layers.Dense(1),\n",
    "                layers.Activation('sigmoid')]\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    arquitectura\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear experimento en wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea el experimento en wandb\n",
    "configuracion = {\n",
    "                    'conv_layers': parametros[\"conv_layers\"],\n",
    "                    'filters_layer_1': parametros[\"filters_layer_1\"],\n",
    "                    'kernel_size': parametros[\"kernel_size\"],\n",
    "                    'strides': parametros[\"strides\"],\n",
    "                    'dense_layers': parametros[\"dense_layers\"],\n",
    "                    'dense_units_1': parametros[\"dense_units_1\"],\n",
    "                    'dropout_rate': parametros[\"dropout_rate\"],\n",
    "                    'batch_size': parametros[\"batch_size\"]\n",
    "                }\n",
    "\n",
    "if parametros[\"conv_layers\"] > 1:\n",
    "    configuracion['filters_layer_2'] = parametros[\"filters_layer_2\"]\n",
    "    if parametros[\"conv_layers\"] > 2:\n",
    "        configuracion['filters_layer_3'] = parametros[\"filters_layer_3\"]\n",
    "\n",
    "if parametros[\"dense_layers\"] > 1:\n",
    "    configuracion['dense_units_2'] = parametros[\"dense_units_2\"]\n",
    "    if parametros[\"dense_layers\"] > 2:\n",
    "        configuracion['dense_units_3'] = parametros[\"dense_units_3\"]\n",
    "\n",
    "run = wandb.init(project=\"CNN_quemaduras_2\", \n",
    "                 entity=\"frantorres14\",\n",
    "                 name=\"_\".join(nombre_canales),\n",
    "                 config=configuracion)\n",
    "\n",
    "config = wandb.config\n",
    "wandb_logger = WandbMetricsLogger(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se entrena el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detiene el entrenamiento cuando el modelo deja de mejorar\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10, #Espera 10 épocas sin mejora antes de detener\n",
    "    restore_best_weights=True #Restaura los pesos de la época con mejor val_loss\n",
    ")\n",
    "\n",
    "#Reduce el learning rate cuando el modelo se estanca\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5, #Reduce el learning rate a la mitad cuando no hay mejora\n",
    "    patience=5, #Espera 5 épocas sin mejora antes de reducir\n",
    "    min_lr=1e-7 #Learning rate mínimo permitido\n",
    ")\n",
    "\n",
    "#Entrena el modelo\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=config.batch_size,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[WandbMetricsLogger(), early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_train, accuracy_train, precision_train, recall_train, f1_train = calculate_metrics(model, X_train, y_train)\n",
    "evaluate_model(model, X_train, y_train, dataset='Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_val, accuracy_val, precision_val, recall_val, f1_val = calculate_metrics(model, X_val, y_val)\n",
    "evaluate_model(model, X_val, y_val, dataset='Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registrar métricas en wandb\n",
    "wandb.log({\"accuracy_train\": accuracy_train,\n",
    "           \"precision_train\": precision_train,\n",
    "           \"recall_train\": recall_train,\n",
    "           \"f1_train\": f1_train,\n",
    "           \"accuracy_val\": accuracy_val,\n",
    "           \"precision_val\": precision_val,\n",
    "           \"recall_val\": recall_val,\n",
    "           \"f1_val\": f1_val})\n",
    "\n",
    "# Termina el experimento\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparámetros a probar\n",
    "\n",
    "'conv_layers': [1, 2, 3]  \n",
    "'filters_layer_k': [16, 32, 64]  \n",
    "'kernel_size': [3, 5]  \n",
    "'strides': [1, 2, 3]  \n",
    "'dense_layers': [1, 2, 3]  \n",
    "'dense_units_k': [32, 64, 128]  \n",
    "'dropout_rate': [0.3, 0.4, 0.5]  \n",
    "'batch_size': [16, 32, 64]  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
